{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data set\n",
    "boston = load_boston()\n",
    "X_data = boston.data\n",
    "y_target = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x, y):\n",
    "    '''\n",
    "    This function implements random forest\n",
    "    '''\n",
    "    y_predicted_val = []\n",
    "    oob = []\n",
    "    y_pred = np.zeros_like(y)\n",
    "    for i in range(0, 30):  #For creating 30 samples\n",
    "        x_bagged = []\n",
    "        y_bagged = []\n",
    "        rows_60 = random.sample(range(0, len(x)), math.floor((len(x) * 60) / 100))  #Randomly creates indices for 60% data\n",
    "        rows_40 = random.sample(rows_60, math.ceil((len(x) * 40) / 100))  #Randomly creates indices for 40% data\n",
    "        number_cols = random.sample(range(3, 14), 1)   #Randomly selects number of columns\n",
    "        cols = random.sample(range(0, 13), number_cols[0])  #Randomly creates indices for columns\n",
    "        for index in rows_60: #Iterates through each index of 60% data\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for k in sorted(cols):   #Iterates through each index of column of a data point\n",
    "                x_data.append(x[index][k])\n",
    "            x_bagged.append(x_data)\n",
    "            y_bagged.append(y[index])\n",
    "        for index in rows_40:  #Iterates through each index of 40% data\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for k in sorted(cols):    #Iterates through each index of column of a data point\n",
    "                x_data.append(x[index][k])\n",
    "            x_bagged.append(x_data)\n",
    "            y_bagged.append(y[index])\n",
    "        x_pred = x[:, sorted(cols)]   #Getting data points with selected columns for prediction\n",
    "        dtr = DecisionTreeRegressor()\n",
    "        dtr.fit(np.array(x_bagged), np.array(y_bagged))\n",
    "        prediction = dtr.predict(x_pred)\n",
    "        y_predicted_val.append(prediction)  #y_predicted_val contains predicted values of each model\n",
    "        y_pred = y_pred + prediction\n",
    "        temp = []\n",
    "        for j in range(0, len(x)):\n",
    "            if j not in rows_60:   #Checking if a data point is oob point, a data point is a oob point if is not in rows_60\n",
    "                temp.append(j)\n",
    "        oob.append(temp)          #Collecting oob points for a model\n",
    "    y_pred = y_pred / 30          #Predicted scores of training data points\n",
    "    val = 0\n",
    "    for i in range(0, len(y)):\n",
    "        val += ((y[i] - y_pred[i]) ** 2)    #Computing squared error\n",
    "    mse = val / len(y)       #Computing mean squared error\n",
    "    oob_pred = []\n",
    "    for i in range(0, len(x)):\n",
    "        count = 0\n",
    "        val = 0\n",
    "        for j in range(0, len(oob)):\n",
    "            if i in oob[j]:    #Checking whether a point is in oob points\n",
    "                val += y_predicted_val[j][i]  # val accumulates the predicted values of a oob point\n",
    "                count += 1                    # count stores the number of models of whose oob points have the data \n",
    "                 # point i\n",
    "        if count != 0:\n",
    "            oob_pred.append(val / count)\n",
    "        else:\n",
    "            oob_pred.append(0)\n",
    "    val = 0\n",
    "    for i in range(0, len(x)):\n",
    "        val += ((y[i] - oob_pred[i]) ** 2) #Computing squared error for oob data points\n",
    "    oob_score = val / len(y)          #Computing OOBScore\n",
    "    return mse, oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.969132358768848\n",
      "OOBScore = 12.61180773839129\n"
     ]
    }
   ],
   "source": [
    "MSE, OOBScore = random_forest(X_data, y_target)\n",
    "print('MSE =', MSE)\n",
    "print('OOBScore =', OOBScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:06<00:00,  5.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "MSE = []\n",
    "OOBScore = []\n",
    "for i in tqdm(range(0, 35)): #Computing 35 times mse and oob_score\n",
    "    mse, oob_score = random_forest(X_data, y_target)\n",
    "    MSE.append(mse)\n",
    "    OOBScore.append(oob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for MSE\n",
      "+-------------+--------------------+---------------------+---------+----------+\n",
      "| Sample Size |    Sample mean     |      Sample std     | Left CI | Right CI |\n",
      "+-------------+--------------------+---------------------+---------+----------+\n",
      "|      35     | 2.4232556386617206 | 0.24990501883446786 |  2.339  |  2.508   |\n",
      "+-------------+--------------------+---------------------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "print('Confidence Interval for MSE')\n",
    "x = PrettyTable()\n",
    "x = PrettyTable(['Sample Size', 'Sample mean', 'Sample std', 'Left CI', 'Right CI'])\n",
    "sample = np.array(MSE)\n",
    "sample_size = len(sample)\n",
    "sample_mean = sample.mean()\n",
    "sample_std = sample.std()\n",
    "left_limit = np.round(sample_mean - 2 * (sample_std / np.sqrt(sample_size)), 3)\n",
    "right_limit = np.round(sample_mean + 2 * (sample_std / np.sqrt(sample_size)), 3)\n",
    "row = []\n",
    "row.append(sample_size)\n",
    "row.append(sample_mean)\n",
    "row.append(sample_std)\n",
    "row.append(left_limit)\n",
    "row.append(right_limit)\n",
    "x.add_row(row)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for OOBScore\n",
      "+-------------+--------------------+-------------------+---------+----------+\n",
      "| Sample Size |    Sample mean     |     Sample std    | Left CI | Right CI |\n",
      "+-------------+--------------------+-------------------+---------+----------+\n",
      "|      35     | 14.059912432668275 | 1.157808047832362 |  13.669 |  14.451  |\n",
      "+-------------+--------------------+-------------------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "print('Confidence Interval for OOBScore')\n",
    "x = PrettyTable()\n",
    "x = PrettyTable(['Sample Size', 'Sample mean', 'Sample std', 'Left CI', 'Right CI'])\n",
    "sample = np.array(OOBScore)\n",
    "sample_size = len(sample)\n",
    "sample_mean = sample.mean()\n",
    "sample_std = sample.std()\n",
    "left_limit = np.round(sample_mean - 2 * (sample_std / np.sqrt(sample_size)), 3)\n",
    "right_limit = np.round(sample_mean + 2 * (sample_std / np.sqrt(sample_size)), 3)\n",
    "row = []\n",
    "row.append(sample_size)\n",
    "row.append(sample_mean)\n",
    "row.append(sample_std)\n",
    "row.append(left_limit)\n",
    "row.append(right_limit)\n",
    "x.add_row(row)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_house_price(x, y, xq):\n",
    "    '''\n",
    "    This function predicts the house price of a query point\n",
    "    '''\n",
    "    y_pred = 0\n",
    "    for i in range(0, 30):  #For creating 30 samples\n",
    "        x_bagged = []\n",
    "        y_bagged = []\n",
    "        x_query = []\n",
    "        rows_60 = random.sample(range(0, 506), math.floor((len(x) * 60) / 100)) #Randomly creates indices for 60% data\n",
    "        rows_40 = random.sample(rows_60, math.ceil((len(x) * 40) / 100))  #Randomly creates indices for 40% data\n",
    "        number_cols = random.sample(range(3, 14), 1) #Randomly selects number of columns\n",
    "        cols = random.sample(range(0, 13), number_cols[0]) #Randomly creates indices for columns\n",
    "        for index in rows_60: #Iterates through each index of 60% data\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for k in sorted(cols):  #Iterates through each index of the column of a data point\n",
    "                x_data.append(x[index][k])\n",
    "            x_bagged.append(x_data)\n",
    "            y_bagged.append(y[index])\n",
    "        for index in rows_40:    #Iterates through each index of 40% data\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for k in cols:  #Iterates through each index of the column of a data point\n",
    "                x_data.append(x[index][k])\n",
    "            x_bagged.append(x_data)\n",
    "            y_bagged.append(y[index])\n",
    "        for k in cols:  #Iterates through each index of the column of the query data point\n",
    "            x_query.append(xq[k])\n",
    "        dtr = DecisionTreeRegressor()\n",
    "        dtr.fit(np.array(x_bagged), np.array(y_bagged))\n",
    "        prediction = dtr.predict((np.array(x_query)).reshape(1, -1))\n",
    "        y_pred += prediction[0]\n",
    "    y_pred /= 30\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted house price is  20.203333333333333\n"
     ]
    }
   ],
   "source": [
    "x_query = np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
    "predicted_house_price = predict_house_price(X_data, y_target, x_query)\n",
    "print('The predicted house price is ', predicted_house_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
